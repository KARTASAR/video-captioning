{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7zb0OUJwI2V",
        "outputId": "105af4a4-0e38-4b91-dee7-eac7f6bf09e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q git+https://github.com/openai/CLIP.git transformers bitsandbytes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVOAT-7vwE87",
        "outputId": "459c90c0-3b05-4581-85f6-1d0ff3eb1428"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 5.8 MB 33.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 62.5 MB 1.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 53 kB 1.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 50.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 182 kB 77.8 MB/s \n",
            "\u001b[?25h  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/drive/MyDrive/Olimpiads/nto_hack_2022/V2/data /content/\n",
        "!unzip -q /content/drive/MyDrive/Olimpiads/nto_hack_2022/V2/videos_train.zip \n",
        "!mv videos_train /content/data\n",
        "\n",
        "!cp -i /content/drive/MyDrive/Olimpiads/nto_hack_2022/V2/config.py /content/\n",
        "!cp -i /content/drive/MyDrive/Olimpiads/nto_hack_2022/V2/utils.py /content/\n",
        "!cp -i /content/drive/MyDrive/Olimpiads/nto_hack_2022/V2/model.py /content/"
      ],
      "metadata": {
        "id": "UZes6zaZMKfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WrsY_C5_HhKd"
      },
      "outputs": [],
      "source": [
        "import bitsandbytes as bnb\n",
        "import gc\n",
        "import io\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import sys\n",
        "\n",
        "import torchvision\n",
        "import transformers\n",
        "import torch\n",
        "from torch.nn import functional as nnf\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "from torch.cuda.amp import autocast\n",
        "\n",
        "from utils import *\n",
        "from model import *\n",
        "from config import CFG\n",
        "\n",
        "from transformers.optimization import Adafactor, AdafactorSchedule\n",
        "from torch.utils.checkpoint import checkpoint_sequential\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CFG.batch_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y29OWOHm8OEo",
        "outputId": "e30bc391-5c88-460e-a8e5-2d36aa567515"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0NNLhOvGHhKi"
      },
      "outputs": [],
      "source": [
        "def get_caption(prefix, model, device, tokenizer, prompt=''):\n",
        "    prefix = prefix.to(device)\n",
        "    with torch.no_grad():\n",
        "\n",
        "        prefix_embed = model.clip_project(prefix).reshape(len(prefix), CFG.prefix_length, -1)\n",
        "\n",
        "        answers = []\n",
        "\n",
        "        for x in range(len(prefix_embed)):\n",
        "\n",
        "            start = time.time()\n",
        "\n",
        "            cur_prefix_embed = prefix_embed[x].unsqueeze(0).to('cpu')\n",
        "            \n",
        "            print('first', time.time()-start)\n",
        "            \n",
        "            if prompt:\n",
        "                generated_text_prefix = generate2(model, tokenizer, prompt=prompt, embed=cur_prefix_embed)\n",
        "            else:\n",
        "                generated_text_prefix = generate2(model, tokenizer, embed=cur_prefix_embed)\n",
        "            \n",
        "            print('second', time.time()-start)\n",
        "        \n",
        "            answers.append(generated_text_prefix.replace('\\n',' ').replace('<|endoftext|',''))\n",
        "\n",
        "    return [x[len(prompt):].strip() for x in answers]\n",
        "\n",
        "# def get_ans(model, clip_emb, prompt, device, tokenizer):\n",
        "#     output = get_caption(clip_emb, model, device, tokenizer, prompt=prompt)\n",
        "#     return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ac6Sfj_cHhKj"
      },
      "outputs": [],
      "source": [
        "def train(train_loader, model, optimizer, scheduler, device, epoch):\n",
        "    loss_avg = AverageMeter()\n",
        "    \n",
        "    model = model.to(device)\n",
        "    model.train()\n",
        "\n",
        "    progress = tqdm(total=len(train_loader))\n",
        "    for idx, (tokens, mask, prefix) in enumerate(train_loader):\n",
        "        model.zero_grad()\n",
        "        tokens, mask, prefix = tokens.to(device), mask.to(device), prefix.to(device, dtype=torch.float32)\n",
        "        \n",
        "        outputs = model(tokens, prefix, mask)\n",
        "        logits = outputs.logits[:, CFG.prefix_length-1: -1]\n",
        "\n",
        "        loss = nnf.cross_entropy(logits.reshape(-1, logits.shape[-1]), tokens.flatten(), ignore_index=0)\n",
        "\n",
        "        segments = 2\n",
        "\n",
        "        # out = checkpoint_sequential(modules, segments, input_var)\n",
        "\n",
        "        loss.backward()    \n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        clipping_value = 0.5 # arbitrary value of your choosing\n",
        "        #torch.nn.utils.clip_grad_norm(model.parameters(), clipping_value)\n",
        "\n",
        "        loss_avg.update(loss.item(), len(mask))\n",
        "        progress.set_description(f\"loss: {loss_avg.avg:.5f}\")\n",
        "        progress.update()\n",
        "        \n",
        "\n",
        "        # del tokens\n",
        "        # del mask\n",
        "        # del prefix\n",
        "        torch.clear_autocast_cache()\n",
        "        torch.cuda.empty_cache()\n",
        "    progress.close()\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def valid(model, valid_loader, device, gt):\n",
        "    loss_avg = AverageMeter()\n",
        "    model.eval()\n",
        "    progress = tqdm(enumerate(valid_loader), total=len(valid_loader))\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained(CFG.backbone)\n",
        "    \n",
        "\n",
        "    all_answers = []\n",
        "    for idx, (tokens, mask, prefix) in progress:\n",
        "        tokens, mask, prefix = tokens.to(device), mask.to(device), prefix.to(device, dtype=torch.float32)\n",
        "        answer = get_caption(prefix, model, device, tokenizer, prompt='Caption: ')\n",
        "        all_answers.append(answer)\n",
        "    score = bleu_metric(gt, np.concatenate(all_answers))\n",
        "    return score\n",
        "    \n",
        "\n",
        "import nltk\n",
        "def bleu_metric(ground_truth, prediction):\n",
        "    scores = []\n",
        "    for gt, pred in zip(ground_truth, prediction):\n",
        "        if type(pred)==str and type(gt)==str:\n",
        "            score = nltk.translate.bleu_score.sentence_bleu([gt.lower().split()], pred.lower().replace('<|endoftext|>','').split(), weights = (0.5, 0.5))\n",
        "        scores+=[score]\n",
        "    return np.array(scores).mean()*100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lrRF84ajHhKl"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    valid_df = pd.read_csv(CFG.valid_df_path)\n",
        "    train_ds = ClipCocoDataset(CFG.train_features_path, CFG.prefix_length)\n",
        "    valid_ds = ClipCocoDataset(CFG.valid_features_path, CFG.prefix_length)\n",
        "\n",
        "    train_loader = DataLoader(train_ds, batch_size=CFG.batch_size, shuffle=True, drop_last=True)\n",
        "    valid_loader = DataLoader(train_ds, batch_size=CFG.batch_size, shuffle=False)\n",
        "\n",
        "    model = ClipCaptionModel(prefix_length = CFG.prefix_length, backbone = CFG.backbone)\n",
        "    device = torch.device('cuda') # xm.xla_device()\n",
        "\n",
        "    if not os.path.exists(CFG.out_dir):\n",
        "        os.makedirs(CFG.out_dir)\n",
        "\n",
        "    # model.load_state_dict(torch.load('/content/drive/MyDrive/Olimpiads/nto_hack_2022/V2/coco_flickr-pretrained.pt', map_location='cpu')) \n",
        "\n",
        "    model.load_state_dict(torch.load('/content/drive/MyDrive/Olimpiads/nto_hack_2022/V2/v2_1.pt', map_location='cpu'))\n",
        "    model = model.to(device)\n",
        "   \n",
        "    #model = freeze(model)\n",
        "\n",
        "    model.train()\n",
        "    optimizer = AdamW(model.parameters(),lr=CFG.learning_rate, betas=(0.9, 0.995))\n",
        "    #optimizer = bnb.optim.Adam8bit(model.parameters(), lr=0.001, betas=(0.9, 0.995))\n",
        "    #optimizer = SM3(model.parameters(),lr=args.lr)\n",
        "    #Adafactor(model.parameters(),scale_parameter=True, relative_step=True, warmup_init=True, lr=None)\n",
        "\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer, num_warmup_steps=CFG.warmup_steps, num_training_steps=CFG.epochs * len(train_loader))\n",
        "    #AdafactorSchedule(optimizer)#num_training_steps=epochs * len(train_loader)\n",
        "\n",
        "    for epoch in range(1, 1+CFG.epochs):\n",
        "        train(train_loader, model, optimizer, scheduler, device, epoch)\n",
        "        valid(model, valid_loader, device, valid_df.caption.tolist()) \n",
        "\n",
        "        if epoch % CFG.save_every==0:\n",
        "            torch.save(model.state_dict(),os.path.join(CFG.out_dir, f\"{CFG.model_name}.pt\"))\n",
        "    \n",
        "main()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Validation"
      ],
      "metadata": {
        "id": "-AZ_uavXhDY8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as nnf\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "from tqdm import tqdm, trange\n",
        "import os\n",
        "import pickle\n",
        "import sys\n",
        "import argparse\n",
        "import json\n",
        "from typing import Tuple, Optional, Union\n",
        "#from torch.cuda.amp import autocast\n",
        "import io\n",
        "import os\n",
        "import PIL\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import transformers\n",
        "import more_itertools\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "#from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset\n",
        "#from tqdm import tqdm\n",
        "from dataclasses import dataclass, field\n",
        "import torchvision.transforms as T\n",
        "import torchvision.transforms.functional as TF\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import clip\n",
        "\n",
        "import transformers\n",
        "\n",
        "from utils import *\n",
        "from model import *\n",
        "import re\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "\n",
        "import time"
      ],
      "metadata": {
        "id": "lgPm_dngtxWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_caption(prefix, prompt=''):\n",
        "        prefix = prefix.to(device)\n",
        "        display(prefix.shape)\n",
        "        with torch.no_grad():\n",
        "\n",
        "            prefix_embed = model.clip_project(prefix).reshape(1, prefix_length, -1)\n",
        "\n",
        "            start = time.time()\n",
        "\n",
        "            if prompt:\n",
        "                generated_text_prefix = generate2(model, tokenizer, prompt=prompt, embed=prefix_embed)\n",
        "            else:\n",
        "                generated_text_prefix = generate2(model, tokenizer, embed=prefix_embed)\n",
        "\n",
        "            print(time.time() - start)\n",
        "\n",
        "        return generated_text_prefix.replace('\\n',' ').replace('<|endoftext|','')\n",
        "\n",
        "def get_ans(clip_emb, prompt):\n",
        "        output = get_caption(clip_emb, prompt=prompt)\n",
        "        ans = output[len(prompt):].strip()\n",
        "        return {'answer': ans}\n",
        "\n",
        "\n",
        "#from tqdm import tqdm, trange\n",
        "\n",
        "\n",
        "\n",
        "# parser = argparse.ArgumentParser()\n",
        "# parser.add_argument('--input_path', default='./input_test.csv', type=str, help='input path')\n",
        "# parser.add_argument('--video_path', default='./videos_val/', type=str, help='input path')\n",
        "# parser.add_argument('--output_path', default='./output/', type=str, help='config path')\n",
        "# args = parser.parse_args()\n",
        "\n",
        "config = dict(\n",
        "        model_path = '/content/drive/MyDrive/Olimpiads/nto_hack_2022/V2/v2_1.pt',\n",
        "        video_path = '/content/data/videos_train/',\n",
        "        val_path = '/content/data/new_valid.csv',\n",
        "        gpt = 'gpt2',\n",
        "        prefix_len = 35\n",
        "    )\n",
        "\n",
        "\n",
        "prefix_length = config['prefix_len']#40\n",
        "\n",
        "device = 'cuda'\n",
        "clip_model, preprocess = clip.load(\"ViT-L/14@336px\", device=device, jit=False)\n",
        "clip_model.to(device)\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(config['gpt'])\n",
        "\n",
        "\n",
        "model_path = config['gpt']\n",
        "model = ClipCaptionModel(prefix_length = prefix_length, backbone = config['gpt'])\n",
        "\n",
        "model.load_state_dict(torch.load(config['model_path'], map_location='cpu'))\n",
        "model.to(device)\n",
        "\n",
        "out_path = 'Features_val.pkl'\n",
        "\n",
        "\n",
        "val_embeddings = []\n",
        "val_captions = []\n",
        "\n",
        "input_test = pd.read_csv(config['val_path'])\n",
        "\n",
        "c = 0\n",
        "for p in tqdm(input_test.paths):\n",
        "         #print(p)\n",
        "         #n= df_eval.iloc[i, 0]#, df_eval.iloc[i, 1]\n",
        "    text = f'Caption:'\n",
        "    path = f'{config[\"video_path\"]}{p}'\n",
        "    try:\n",
        "        video = read_video(path, transform=None,frames_num=1)\n",
        "\n",
        "        i = image_grid(video,1,1)\n",
        "        image = preprocess(i).unsqueeze(0).to(device)\n",
        "\n",
        "        # image = make_images(video)\n",
        "        # new_images = []\n",
        "        # for img in image:\n",
        "        #     new_images.append(preprocess(img).unsqueeze(0))\n",
        "\n",
        "        with torch.no_grad():\n",
        "            prefix = clip_model.encode_image(image).to(device, dtype=torch.float32)\n",
        "            # prefix_embed = model.clip_project(prefix).reshape(1, prefix_length, -1)\n",
        "        val_embeddings.append(prefix)\n",
        "        val_captions.append(text)\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "\n",
        "    c+=1\n",
        "    if c > 50:\n",
        "        break\n",
        "\n",
        "answers = []\n",
        "for i in tqdm(range(len(val_embeddings))):\n",
        "        emb = val_embeddings[i]\n",
        "\n",
        "        #qid = df_eval.iloc[i, 2]\n",
        "        ans = get_ans(emb, 'Caption: ')\n",
        "        answers.append(ans['answer'])\n",
        "\n",
        "\n",
        "df = pd.DataFrame({'captions':answers})\n",
        "df.to_csv('/content/data/answer.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JvJqCDjBhFqc",
        "outputId": "f21d9d34-7861-4391-9b28-300ae387d7be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  4%|▍         | 50/1131 [00:33<12:12,  1.48it/s]\n",
            "  0%|          | 0/51 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 1/51 [00:00<00:15,  3.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.3034696578979492\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 2/51 [00:00<00:09,  5.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.09210205078125\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 3/51 [00:00<00:11,  4.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.31274938583374023\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.08498620986938477\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|▉         | 5/51 [00:01<00:09,  4.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.23816752433776855\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 6/51 [00:01<00:10,  4.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2779276371002197\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▎        | 7/51 [00:01<00:08,  4.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.1304011344909668\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 8/51 [00:01<00:11,  3.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.39212965965270996\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 9/51 [00:02<00:09,  4.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.11242198944091797\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|█▉        | 10/51 [00:02<00:07,  5.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.09522724151611328\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 11/51 [00:02<00:10,  3.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4285433292388916\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▎       | 12/51 [00:03<00:15,  2.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7149248123168945\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 13/51 [00:03<00:13,  2.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2564268112182617\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 14/51 [00:03<00:12,  2.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2703378200531006\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▉       | 15/51 [00:04<00:15,  2.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6493005752563477\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.07866024971008301\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 17/51 [00:04<00:09,  3.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.15224575996398926\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 18/51 [00:05<00:13,  2.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7770967483520508\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 19/51 [00:05<00:10,  2.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.12859082221984863\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 39%|███▉      | 20/51 [00:06<00:11,  2.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.43067240715026855\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████      | 21/51 [00:06<00:11,  2.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.3566253185272217\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 22/51 [00:06<00:08,  3.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.1589794158935547\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▌     | 23/51 [00:06<00:07,  3.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.20769381523132324\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 24/51 [00:07<00:06,  3.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.17076396942138672\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|████▉     | 25/51 [00:07<00:07,  3.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.306041955947876\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.07049560546875\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 27/51 [00:07<00:04,  5.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.10656166076660156\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▍    | 28/51 [00:07<00:05,  4.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.40012168884277344\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 29/51 [00:08<00:04,  4.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.12095379829406738\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▉    | 30/51 [00:08<00:05,  4.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.33652377128601074\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 61%|██████    | 31/51 [00:08<00:04,  4.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.23685932159423828\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 32/51 [00:08<00:05,  3.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.3125741481781006\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▍   | 33/51 [00:09<00:05,  3.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.3499138355255127\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 34/51 [00:09<00:04,  3.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.1642293930053711\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0750422477722168\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████   | 36/51 [00:09<00:02,  5.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.10628890991210938\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 37/51 [00:10<00:03,  4.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.37145566940307617\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▍  | 38/51 [00:10<00:03,  3.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.36944079399108887\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▋  | 39/51 [00:10<00:02,  4.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.16354870796203613\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 40/51 [00:10<00:02,  4.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.1637716293334961\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 41/51 [00:11<00:02,  4.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.1833963394165039\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 42/51 [00:11<00:02,  3.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.35005927085876465\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 43/51 [00:11<00:02,  3.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2335970401763916\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▋ | 44/51 [00:11<00:01,  4.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.14165067672729492\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 45/51 [00:11<00:01,  5.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.11670351028442383\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 46/51 [00:12<00:00,  5.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.12346720695495605\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 47/51 [00:12<00:00,  6.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.1095726490020752\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.07436227798461914\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 49/51 [00:12<00:00,  5.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.3842051029205322\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 50/51 [00:12<00:00,  5.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.11292529106140137\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r100%|██████████| 51/51 [00:12<00:00,  3.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.08947086334228516\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_pred = '/content/data/answer.csv'\n",
        "df_pred = pd.read_csv(path_pred)\n",
        "new_preds = []\n",
        "for x in df_pred['captions']:\n",
        "    a = ''\n",
        "    if x is not np.nan:\n",
        "        for y in x:\n",
        "            if re.findall(r'[A-Za-z0-9 \\.\\,\\-]', y):\n",
        "                a += y\n",
        "    new_preds.append(a)\n",
        "df_pred['captions'] = new_preds\n",
        "df_pred.to_csv('/content/data/new_answer.csv', index=False)"
      ],
      "metadata": {
        "id": "H3ETUSlzhM4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "import numpy as np\n",
        "\n",
        "path_gt = '/content/data/new_valid.csv'\n",
        "path_pred = '/content/data/answer.csv'\n",
        "df_eval = pd.read_csv(path_gt)\n",
        "df_pred = pd.read_csv(path_pred)\n",
        "scores = []\n",
        "for pred, gt in zip(df_eval.caption, df_pred.captions):\n",
        "    if type(pred)==str and type(gt)==str:\n",
        "        score = nltk.translate.bleu_score.sentence_bleu([gt.lower().split()], pred.lower().replace('<|endoftext|>','').split(), weights = (0.5, 0.5))\n",
        "    scores+=[score]\n",
        "ans = np.array(scores).mean()*100\n",
        "print(round(ans, 5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGnoa9E-hOhq",
        "outputId": "cdb1b93c-f41e-4b2e-daf2-dac61292c28a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7.11994\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(50):\n",
        "    print(df_eval.caption.tolist()[i])\n",
        "    print(df_pred.captions.tolist()[i])\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0poVoXthQG-",
        "outputId": "88cdb531-99da-4e43-d0a1-96c31b0b20e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beautiful blue and yellow flowers in an arrangement close-up, pan shot.\n",
            "Bouquet of little pink flowers of different colors and sizes\n",
            "\n",
            "Dirty car bumper\n",
            "Cars driving in a highway\n",
            "\n",
            "Girl running on the street with masks, front view and close to the shot, with the panorama of the street out of focus in the background, with cars, trees, the sidewalk and the sun lighting up.\n",
            "A woman in a black mask runs through the park with her hands on her feet, surrounded by trees and buildings.\n",
            "\n",
            "Woman with a hat watching the ocean\n",
            "A calm sea and mountains\n",
            "\n",
            "Married couple receiving at the door of their house another neighbor couple who arrived with welcome gifts, while smiling happily.\n",
            "Happy businessman gives a thumbs up as he hugs his girlfriend during a break on a date.\n",
            "\n",
            "View under a bridge that crosses a river in a big city, where some people go sailing by boat underneath.\n",
            "A group of people rowing on a river surrounded by trees and buildings, during a sunny day.\n",
            "\n",
            "Guangzhou illuminated cityscape with cloudy sky\n",
            "Shanghai bridge and the sky flashing in the night\n",
            "\n",
            "Black-haired, urban-fashion dancer dancing hip hop in the parking lot of a building.\n",
            "Young black haired girl dances hip hop in urban dance clothes in a place with flashing lights and a pickup truck with people passing by in the background.\n",
            "\n",
            "Man chatting with two women in a cafe\n",
            "A couple talking in a coffee shop\n",
            "\n",
            "Summer lake\n",
            "Swans swimming in a lake\n",
            "\n",
            "Fast motion shot of a busy street with people and cars crossing in the city\n",
            "Many people cross the street in a wide shot from above with their hands on their heads, as cars pass by and people cross the sidewalks with their lights on.\n",
            "\n",
            "Running track blue with white lines seen up close in a slow course, starting from the numbers in the starting area.\n",
            "Close up of the legs of a runner in a running race while running long stretches in the background.\n",
            "\n",
            "Sunset in Greece from the coast\n",
            "A sunset seen from the sea that covers a forest with clouds that travel with the wind.\n",
            "\n",
            "Path under a peripheral road, while cars pass quickly in the avenues to the sides, while the take turns up slowly.\n",
            "A busy avenue with many people walking and crossing it, during a dusk.\n",
            "\n",
            "A burger is made with a fried egg and honey on a white plate with fries on one side.\n",
            "A person's hand cutting a hamburger in half with a knife in front of a plate of eggs.\n",
            "\n",
            "House in the middle of the ocean\n",
            "People on the beach\n",
            "\n",
            "An aerial landscape of a mountainous forest during spring with a blue sky with some clouds.\n",
            "Rocky mountains during a sunny day in the mountains.\n",
            "\n",
            "Hands of a person with a smartphone, while preparing a post of his coffee with a donut, with an emoji of heart eyes.\n",
            "A person sitting in a dining room checking his smartphone while stewing in a coffee pot with marshmallows and a cup of tea.\n",
            "\n",
            "Kittens playing in a garden\n",
            "A couple of cats playing in the sand\n",
            "\n",
            "Aerial shot of a large avenue at night in Guadalajara, Jalisco in Mexico, with many cars traveling along it.\n",
            "Aerial view of a long avenue of a big city in Guadalajara in Jalisco, Mexico at night, with cars going through its streets.\n",
            "\n",
            "Child talking to his Husky\n",
            "A person wearing a winter hat gives a hula hoop to a dog in a fenced in place in the winter forest.\n",
            "\n",
            "Beijing cityscape with traffic at daytime\n",
            "Cars drive in a wide city during a sunny day\n",
            "\n",
            "Snowy pine forest illuminated with light of dusk that is looming on the horizon with a lake that reflects light from the sun.\n",
            "A lake illuminated by a rainbow of pink and red lights during a sunset.\n",
            "\n",
            "Far frontal shot of an active volcano smoking on a clear, sunny day.\n",
            "Clouds moving in a clear sky with a cloud in the background\n",
            "\n",
            "Young boy pointing at city lights\n",
            "A mother and her daughter dancing in the street at night, while the two smile and huddle together in the background\n",
            "\n",
            "Laying out sandwich ingredients\n",
            "A person slices bread\n",
            "\n",
            "Sunset sunlight glaring in a wintry forest\n",
            "Snowy pine trees receiving the sun\n",
            "\n",
            "Work group planning an architectural project\n",
            "A team of four people discuss a plan with a whiteboard during a work meeting in a white room with yellow tables and a blue wall behind them.\n",
            "\n",
            "Water jets from a fountain under trees.\n",
            "Silhouette of water from a fountain\n",
            "\n",
            "Flying over a roundabout in the city of Guadalajara at night, while many cars turn around it in the middle of the traffic.\n",
            "A couple of small buildings in the city during a cloudy afternoon, with mountains and the pink clouds above in the sky.\n",
            "\n",
            "Point of view going down a curved highway going down a mountain covered with trees and grass, and surrounded by other mountains.\n",
            "A road in a rural country with mountains in the background and clouds passing at high speed\n",
            "\n",
            "Girl descending from a very high wall for mountaineering, held by a harness, in the open air.\n",
            "Young man climbing to the top of a huge outdoor mountain gym with ropes and a harness, in an aerial shot.\n",
            "\n",
            "Very inspired musician playing the saxophone, elegantly dressed in a red jacket and hat, on a dark background.\n",
            "A talented musician skillfully and skillfully playing a blue electric guitar and a dark blue trombone, in a dark room.\n",
            "\n",
            "Sunset on a day with clouds and fog behind the silhouette of mountains.\n",
            "The sky gradually rising with the clouds in the background\n",
            "\n",
            "Smiling woman covers face with heart cutout in snowy street\n",
            "Happy girl enjoying Christmas\n",
            "\n",
            "Going through the clouds on a night flight\n",
            "Beautiful clouds moving in the sky\n",
            "\n",
            "Married couple running through trees\n",
            "A couple wearing white wedding dresses walk through a field of green grass with flowers, while the bride wears a bouquet of white roses.\n",
            "\n",
            "Faces of two girls on a friend date in a cafe, eating desserts and milkshakes, chatting and laughing.\n",
            "Two friends laugh and talk during a date with friends in a cafeteria, while they serve bread with milk and a side of cottage cheese.\n",
            "\n",
            "Truck passing by some wild horses in the desert\n",
            "A couple of motocross horses running in a desert\n",
            "\n",
            "Mother working on her laptop with her son\n",
            "Mom on her computer while taking care of her son\n",
            "\n",
            "Descending platforms in the form of colored clouds\n",
            "Animation of a colorful fractal tunnel on a red background.\n",
            "\n",
            "Boy surprising his girlfriend with a rose, who hugs him happily, in a romantic coffee shop.\n",
            "A girl and a boy dressed in brown shirts and sweats play ball with each other in a colorful outdoor cafe during a date.\n",
            "\n",
            "Time lapse of traffic on an avenue in a city at night with buildings in the background.\n",
            "Time lapse of a highway with fast traffic in LA and buildings horizon and night.\n",
            "\n",
            "Water goes down the drain in the bathroom\n",
            "A white toilet in a black and white pan\n",
            "\n",
            "Hourglass in the middle of a sand desert\n",
            "Camelot playing ball in the desert\n",
            "\n",
            "People get down from the tram\n",
            "Pigeons walking on a city street\n",
            "\n",
            "Aerial tour above a huge plain of sand covered with water, surrounded by great mountains.\n",
            "People walking on the beach at sunset\n",
            "\n",
            "Family chatting on Christmas Day\n",
            "Family praying at Christmas\n",
            "\n",
            "A person wearing a black leather jacket, blue jeans and a white helmet rides a motorcycle on a road, in the background one other car on the road and green hills covered in trees.\n",
            "A man wearing a gray jacket and a black helmet rides a motorcycle on a highway as cars drive by on both sides of the road.\n",
            "\n",
            "Stadium in the snow\n",
            "Nightfall under a illuminated football stadium\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.8.15 ('venv_2')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.15"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "250a20577d0e1585cf7cc86e322aaf8568310437361837b38f6682d9b9966bc7"
      }
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}